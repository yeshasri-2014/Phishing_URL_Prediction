{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phishing URL's Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Problem Statement](#section1)</br>\n",
    "    - 1.1 [Introduction](#section101)<br/>\n",
    "    - 1.2 [Data source and data set](#section102)<br/>\n",
    "2. [Load the packages and data](#section2)</br>\n",
    "    - 2.1 [Description about each column in the dataset](#section201)<br/>\n",
    "3. [Data profiling](#section3)</br>\n",
    "    - 3.1 [Initial Profiling Observations](#section3.1)<br/>\n",
    "    - 3.2 [Final Profiling observations](#section3.2)<br/>\n",
    "4. [Model evaluation](#section4)</br>\n",
    "    - 4.1 [Loading the train and test datasets](#section4.1)</br>\n",
    "    - 4.2 [Logistic regression](#section4.2)</br>\n",
    "    - 4.3 [Decision Tree Regressor with Default values](#section4.3)</br>\n",
    "    - 4.4 [Decision tree with Grid Search CV](#section4.4)</br>\n",
    "    - 4.5 [RF with best hyper parameters](#section4.5)</br>\n",
    "    - 4.6 [Navie Bayes](#section4.6)</br>\n",
    "    - 4.7 [Stochastic Gradient Descent](#section4.7)</br>\n",
    "    - 4.8 [K-Nearest Neighbours](#section4.8)</br>\n",
    "    - 4.9 [SVM](#section4.9)</br>\n",
    "    - 4.10 [Ensemble Bagging - voting classifier](#section4.10)</br>\n",
    "    - 4.11 [AdaBoost](#section4.11)</br>\n",
    "    - 4.12 [Gradient Boosting](#section4.12)</br>\n",
    "    - 4.13 [XGBoost](#section4.13)</br>\n",
    "    - 4.14 [Conclusion and model selection](#section4.14)</br>\n",
    "5. [Model Deployment](#section5)</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section1></a> \n",
    "## 1. Problem Statement \n",
    "\n",
    "\"Detecting the phishing URL using the machine learning algorithms - The openness of the Web exposes opportunities for criminals to upload malicious content. In fact, despite extensive research, email based spam filtering techniques are unable to protect other web services. Therefore, a counter measure must be taken that generalizes across web services to protect the user from phishing host URLs.\"\n",
    "\n",
    "<a id=section101></a> \n",
    "### 1.1. Introduction\n",
    "Phishing is popular among attackers, since it is easier to trick someone into clicking a malicious link which seems legitimate than trying to break through a computer’s defense systems. The malicious links within the body of the message are designed to make it appear that they go to the spoofed organization using that organization’s logos and other legitimate contents.\n",
    "\n",
    "<a id=section102></a> \n",
    "### 1.2. Data source and dataset\n",
    "\n",
    "__a__. How was it collected? \n",
    "\n",
    "- This data set if collected from UCI - machine learning respository\n",
    "\n",
    "- __Description__: \"This data set is prepared by UCI by combining 31 different attribuites which were useful in classification a website URL as phishing or not\"\n",
    "\n",
    "__b__. Is it a sample? If yes, was it properly sampled?\n",
    "- No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section2></a> \n",
    "## 2. Load the packages and data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this line in case you dont have sklearn installed.\n",
    "```python\n",
    "!pip install sklearn\n",
    "```      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import warnings # Ignore warning related to pandas_profiling\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the actual data into the dataframe\n",
    "ds = pd.read_csv(\"dataset.csv\")\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section201></a> \n",
    "### 2.1. Description about each column in the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters in dataset\n",
    "\n",
    "Each value in the dataset contains below items which are seperated by a comma.\n",
    "\n",
    "- having_IP_Address { -1,1 }\n",
    "- URL_Length { 1,0,-1 }\n",
    "- Shortining_Service { 1,-1 }\n",
    "- having_At_Symbol { 1,-1 }\n",
    "- double_slash_redirecting { -1,1 }\n",
    "- Prefix_Suffix { -1,1 }\n",
    "- having_Sub_Domain { -1,0,1 }\n",
    "- SSLfinal_State { -1,1,0 }\n",
    "- Domain_registeration_length { -1,1 }\n",
    "- Favicon { 1,-1 }\n",
    "- port { 1,-1 }\n",
    "- HTTPS_token { -1,1 }\n",
    "- Request_URL { 1,-1 }\n",
    "- URL_of_Anchor { -1,0,1 }\n",
    "- Links_in_tags { 1,-1,0 }\n",
    "- SFH { -1,1,0 }\n",
    "- Submitting_to_email { -1,1 }\n",
    "- Abnormal_URL { -1,1 }\n",
    "- Redirect { 0,1 }\n",
    "- on_mouseover { 1,-1 }\n",
    "- RightClick { 1,-1 }\n",
    "- popUpWidnow { 1,-1 }\n",
    "- Iframe { 1,-1 }\n",
    "- age_of_domain { -1,1 }\n",
    "- DNSRecord { -1,1 }\n",
    "- web_traffic { -1,0,1 }\n",
    "- Page_Rank { -1,1 }\n",
    "- Google_Index { 1,-1 }\n",
    "- Links_pointing_to_page { 1,0,-1 }\n",
    "- Statistical_report { -1,1 }\n",
    "- Result { -1,1 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section3></a> \n",
    "## 3. Data Profiling\n",
    "\n",
    "Review the data types and sample data to understand what variables we are dealing with?<br>\n",
    "Which variables need to be transformed in some way before they can be analyzed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping columns to the name in the dataset so that we can easy related name to value\n",
    "ds_columns=[\"having_IP_Address\",\"URL_Length\",\"Shortining_Service\",\"having_At_Symbol\",\"double_slash_redirecting\",\"Prefix_Suffix\",\n",
    "            \"having_Sub_Domain\",\"SSLfinal_State\",\"Domain_registeration_length\",\"Favico\",\"port\",\"HTTPS_token\",\"Request_URL\",\n",
    "            \"URL_of_Anchor\",\"Links_in_tags\",\"SFH\",\"Submitting_to_email\",\"Abnormal_URL\",\"Redirect\",\"on_mouseover\",\"RightClick\",\n",
    "            \"popUpWindow\",\"Iframe\", \"age_of_domain\",\"DNSRecord\",\"web_traffic\",\"Page_Rank\",\"Google_Index\",\n",
    "            \"Links_pointing_to_page\",\"Statistical_report\",\"Result\"]\n",
    "\n",
    "indexed_ds=pd.DataFrame(ds.values,columns=ds_columns)\n",
    "indexed_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are not using Favicon,port,Request_URL,URL_of_Anchor,Links_in_tags,SFH,web_traffic and Statistical_report\n",
    "#dataset size\n",
    "indexed_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_ds.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for NAN/missing values in the dataset\n",
    "indexed_ds.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the correlation between different variables\n",
    "indexed_ds.corr()['Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation map to see how features are correlated with Results\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "corrmat = indexed_ds.corr()\n",
    "plt.subplots(figsize=(12,9))\n",
    "sns.heatmap(corrmat, vmax=0.9, square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section3.1></a> \n",
    "### 3.1. Observations\n",
    " - We have 31 columns which are type interger\n",
    " - Correlation between \"Result\" and Iframe(-0.003362),Favico(-0.000231),popUpWindow(0.000136) is almost zero,we can drop them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del indexed_ds[\"Favico\"]\n",
    "del indexed_ds[\"Iframe\"]\n",
    "del indexed_ds['popUpWindow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del indexed_ds[\"Favico\"]\n",
    "#del indexed_ds[\"port\"]\n",
    "#del indexed_ds[\"Request_URL\"]\n",
    "#del indexed_ds[\"URL_of_Anchor\"]\n",
    "#del indexed_ds[\"Links_in_tags\"]\n",
    "#del indexed_ds[\"SFH\"]\n",
    "indexed_ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section4></a>\n",
    "## 4. Model evaluation\n",
    "- We will use __accuracy score __  for evaluation using different ML classification algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section4.1></a>\n",
    "### 4.1 Loading the train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = 'Result'\n",
    "y = indexed_ds[y_col]\n",
    "\n",
    "#Configure X as other columns except Result\n",
    "X = indexed_ds.iloc[:,:-1]\n",
    "\n",
    "#Split the test and traning data as 80:20 ratio\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculate_error(test, pred):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy, precision, recall and F-score for test and predict data\n",
    "    \"\"\"\n",
    "    print('Accuracy score for test data is:', accuracy_score(test,pred))\n",
    "    print(pd.DataFrame(confusion_matrix(test,pred,labels=[-1, 1]),index=['Actual:-1','Actual:1'],columns=['Pred:-1','Pred:1']))\n",
    "    print(classification_report(test, pred))\n",
    "    #print(np.count_nonzero(test==1), np.count_nonzero(test==-1))\n",
    "    #print(np.count_nonzero(pred==1), np.count_nonzero(pred==-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section4.2></a>\n",
    "### 4.2 Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr =  LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred=lr.predict(X_test)\n",
    "\n",
    "calculate_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "- From the above table we can say that accuracy is same as F-score, which means model is working as expected\n",
    "- Higher Precision means smaller number of False Positives\n",
    "- Higher Recall means smaller number of False Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section4.3></a>\n",
    "### 4.3 Decision tree with default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DT with default values\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "dt = tree.DecisionTreeClassifier(random_state = 0)\n",
    "dt.fit(X_train, y_train)  \n",
    "\n",
    "y_pred = dt.predict(X_test) \n",
    "\n",
    "calculate_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "- From the above table we can say that accuracy is same as F-score, which means model is working as expected\n",
    "- Higher Precision means smaller number of False Positives\n",
    "- Higher Recall means smaller number of False Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section4.4></a>\n",
    "### 4.4 Decision tree with Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DT with GridSearch CV\n",
    "grid_model = tree.DecisionTreeClassifier(random_state = 0)  \n",
    "\n",
    "param_grid = {'min_samples_split':range(2,10,1), 'max_features':[0.5,0.8,0.9,'auto']}\n",
    "grid_search = GridSearchCV(grid_model,param_grid,cv=10, refit='AUC')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "calculate_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "- From the above table we can say that accuracy is same as F-score, which means model is working as expected\n",
    "- Higher Precision means smaller number of False Positives\n",
    "- Higher Recall means smaller number of False Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section4.5></a>\n",
    "### 4.5 RF with best hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF with best hyper parameters\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators':[10,50,100,200], 'min_samples_split':range(2,10,1), 'max_features':[0.5,0.8,0.9,'auto']}\n",
    "\n",
    "n_iter_search = 20\n",
    "search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_grid, return_train_score=True,n_iter=n_iter_search, cv=5, n_jobs=-1)\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        \n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "            \n",
    "\n",
    "from time import time\n",
    "start = time()\n",
    "search.fit(X_train, y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(search.cv_results_)\n",
    "\n",
    "print(\"model Test score: %.3f\" % search.score(X_test, y_test))\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(**search.best_params_)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "#print(\"model score: %.3f\" % clf.score(X_test, y_test))\n",
    "calculate_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "- From the above table we can say that accuracy is same as F-score, which means model is working as expected\n",
    "- Higher Precision means smaller number of False Positives\n",
    "- Higher Recall means smaller number of False Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section4.6></a>\n",
    "### 4.6 Navie Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Navie Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb =  GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred=nb.predict(X_test)\n",
    "#print('Accuracy score for test data is:', accuracy_score(y_test,y_pred))\n",
    "calculate_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "- From the above table we can see that accuracy > F-score, which means model is not working as expected\n",
    "- Precision is largely varing for different predictions(-1 and 1) when compared to other models.\n",
    "- Recall is 1 when predicting outcome as \"-1\" which means model is baised towards \"-1\" due to which False negatives has gradually increased.\n",
    "- Incase of predicting \"1\" recall is < 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section4.7></a>\n",
    "### 4.7 Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic Gradient Descent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd =  SGDClassifier(loss='modified_huber', shuffle=True,random_state=101)\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred=sgd.predict(X_test)\n",
    "#print('Accuracy score for test data is:', accuracy_score(y_test,y_pred))\n",
    "calculate_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "- From the above table we can say that accuracy is same as F-score, which means model is working as expected\n",
    "- Higher Precision means smaller number of False Positives\n",
    "- Higher Recall means smaller number of False Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section4.8></a>\n",
    "### 4.8 K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Nearest Neighbours\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "error_rate = []\n",
    "for i in range(1,51):    \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(range(1,51),error_rate,color='darkred', marker='o',markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can choose 7 as we have elbow there\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "print('Accuracy score for test data is:', accuracy_score(y_test,y_pred))\n",
    "calculate_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "- From the above table we can say that accuracy is same as F-score, which means model is working as expected\n",
    "- Higher Precision means smaller number of False Positives\n",
    "- Higher Recall means smaller number of False Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section4.9></a>\n",
    "### 4.9 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm =  SVC(kernel=\"rbf\", C=0.025,random_state=101)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred=svm.predict(X_test)\n",
    "#print('Accuracy score for test data is:', accuracy_score(y_test,y_pred))\n",
    "calculate_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "- From the above table we can say that accuracy is same as F-score, which means model is working as expected\n",
    "- Higher Precision means smaller number of False Positives\n",
    "- Higher Recall means smaller number of False Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section4.10></a>\n",
    "### 4.10 Ensemble Bagging - voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensemble Bagging - voting classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "model1 = LogisticRegression(random_state=1)\n",
    "model2 = tree.DecisionTreeClassifier(random_state=1)\n",
    "model3 = RandomForestClassifier(**search.best_params_)\n",
    "\n",
    "en_voting = VotingClassifier(estimators=[('lr', model1),('dt', model2), ('rf',model3)], voting='hard')\n",
    "en_voting.fit(X_train,y_train)\n",
    "\n",
    "y_pred=en_voting.predict(X_test)\n",
    "calculate_error(y_test,y_pred)\n",
    "#print('Accuracy score for test data is:', accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "- From the above table we can say that accuracy is same as F-score, which means model is working as expected\n",
    "- Higher Precision means smaller number of False Positives\n",
    "- Higher Recall means smaller number of False Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section4.11></a>\n",
    "### 4.11 AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_boost = AdaBoostClassifier(random_state=1)\n",
    "ada_boost.fit(X_train, y_train)\n",
    "\n",
    "y_pred=ada_boost.predict(X_test)\n",
    "#print('Accuracy score for test data is:', accuracy_score(y_test,y_pred))\n",
    "calculate_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "- From the above table we can say that accuracy is same as F-score, which means model is working as expected\n",
    "- Higher Precision means smaller number of False Positives\n",
    "- Higher Recall means smaller number of False Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section4.12></a>\n",
    "### 4.12 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gra_boost= GradientBoostingClassifier(learning_rate=0.01,random_state=1)\n",
    "gra_boost.fit(X_train, y_train)\n",
    "\n",
    "y_pred=gra_boost.predict(X_test)\n",
    "#print('Accuracy score for test data is:', accuracy_score(y_test,y_pred))\n",
    "calculate_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "- From the above table we can say that accuracy is same as F-score, which means model is working as expected\n",
    "- Higher Precision means smaller number of False Positives\n",
    "- Higher Recall means smaller number of False Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section4.12></a>\n",
    "### 4.13 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "import xgboost as xgb\n",
    "xg_boost=xgb.XGBClassifier(random_state=1,learning_rate=0.01)\n",
    "xg_boost.fit(X_train, y_train)\n",
    "\n",
    "y_pred=xg_boost.predict(X_test)\n",
    "#print('Accuracy score for test data is:', accuracy_score(y_test,y_pred))\n",
    "calculate_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "- From the above table we can say that accuracy is same as F-score, which means model is working as expected\n",
    "- Higher Precision means smaller number of False Positives\n",
    "- Higher Recall means smaller number of False Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section4.14></a>\n",
    "### 4.14 Conclusion and model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Out of all the above classification algorithms RF with hyper parameter tuning and Ensembling voting classifier has acheived higher accuracy score of 97%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section5></a> \n",
    "## 5. Model Deployment\n",
    "- Deplopying the RF randomized CV model using the python pickle model\n",
    "- Provided the REST interface to test the model\n",
    "- Run the deploy.ipynb to access the rest interface for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf, open(\"model.pkl\",\"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
